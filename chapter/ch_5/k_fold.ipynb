{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-fold Cross Validation 을 이용한 집값 예측 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>x9</th>\n",
       "      <th>x10</th>\n",
       "      <th>x11</th>\n",
       "      <th>x12</th>\n",
       "      <th>x13</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.034633</td>\n",
       "      <td>0.206919</td>\n",
       "      <td>0.137057</td>\n",
       "      <td>0.540526</td>\n",
       "      <td>0.193941</td>\n",
       "      <td>0.699239</td>\n",
       "      <td>0.630532</td>\n",
       "      <td>0.239410</td>\n",
       "      <td>0.027375</td>\n",
       "      <td>0.209857</td>\n",
       "      <td>0.347609</td>\n",
       "      <td>0.996394</td>\n",
       "      <td>0.102644</td>\n",
       "      <td>0.422222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.028920</td>\n",
       "      <td>0.014315</td>\n",
       "      <td>0.276113</td>\n",
       "      <td>0.255945</td>\n",
       "      <td>0.618886</td>\n",
       "      <td>0.555407</td>\n",
       "      <td>0.782263</td>\n",
       "      <td>0.482977</td>\n",
       "      <td>0.103031</td>\n",
       "      <td>0.106690</td>\n",
       "      <td>0.520776</td>\n",
       "      <td>0.996650</td>\n",
       "      <td>0.187120</td>\n",
       "      <td>0.368889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.020627</td>\n",
       "      <td>0.033230</td>\n",
       "      <td>0.281116</td>\n",
       "      <td>0.525591</td>\n",
       "      <td>0.165269</td>\n",
       "      <td>0.624102</td>\n",
       "      <td>0.586005</td>\n",
       "      <td>0.272713</td>\n",
       "      <td>0.036010</td>\n",
       "      <td>0.106986</td>\n",
       "      <td>0.595301</td>\n",
       "      <td>0.983284</td>\n",
       "      <td>0.084079</td>\n",
       "      <td>0.660000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.022749</td>\n",
       "      <td>0.033801</td>\n",
       "      <td>0.125044</td>\n",
       "      <td>0.263253</td>\n",
       "      <td>0.251509</td>\n",
       "      <td>0.658532</td>\n",
       "      <td>0.432160</td>\n",
       "      <td>0.344932</td>\n",
       "      <td>0.150018</td>\n",
       "      <td>0.068317</td>\n",
       "      <td>0.651297</td>\n",
       "      <td>0.989989</td>\n",
       "      <td>0.015990</td>\n",
       "      <td>0.631111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.022148</td>\n",
       "      <td>0.029374</td>\n",
       "      <td>0.121057</td>\n",
       "      <td>0.521126</td>\n",
       "      <td>0.399670</td>\n",
       "      <td>0.448086</td>\n",
       "      <td>0.520158</td>\n",
       "      <td>0.495342</td>\n",
       "      <td>0.104383</td>\n",
       "      <td>0.069360</td>\n",
       "      <td>0.560116</td>\n",
       "      <td>0.998723</td>\n",
       "      <td>0.092782</td>\n",
       "      <td>0.693333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>0.028702</td>\n",
       "      <td>0.019528</td>\n",
       "      <td>0.455716</td>\n",
       "      <td>0.097575</td>\n",
       "      <td>0.576859</td>\n",
       "      <td>0.588769</td>\n",
       "      <td>0.654701</td>\n",
       "      <td>0.188444</td>\n",
       "      <td>0.007595</td>\n",
       "      <td>0.165409</td>\n",
       "      <td>0.736795</td>\n",
       "      <td>0.982923</td>\n",
       "      <td>0.219891</td>\n",
       "      <td>0.386667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>0.034217</td>\n",
       "      <td>0.009498</td>\n",
       "      <td>0.490485</td>\n",
       "      <td>0.372934</td>\n",
       "      <td>0.532351</td>\n",
       "      <td>0.580505</td>\n",
       "      <td>0.750547</td>\n",
       "      <td>0.143776</td>\n",
       "      <td>0.051186</td>\n",
       "      <td>0.166428</td>\n",
       "      <td>0.867950</td>\n",
       "      <td>0.995114</td>\n",
       "      <td>0.207453</td>\n",
       "      <td>0.346667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>0.035352</td>\n",
       "      <td>0.021495</td>\n",
       "      <td>0.423918</td>\n",
       "      <td>0.397988</td>\n",
       "      <td>0.349407</td>\n",
       "      <td>0.610529</td>\n",
       "      <td>0.907637</td>\n",
       "      <td>0.087385</td>\n",
       "      <td>0.083448</td>\n",
       "      <td>0.164870</td>\n",
       "      <td>0.782704</td>\n",
       "      <td>0.995791</td>\n",
       "      <td>0.094044</td>\n",
       "      <td>0.420000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>0.026182</td>\n",
       "      <td>0.028603</td>\n",
       "      <td>0.443442</td>\n",
       "      <td>0.509663</td>\n",
       "      <td>0.229142</td>\n",
       "      <td>0.667841</td>\n",
       "      <td>0.867135</td>\n",
       "      <td>0.236241</td>\n",
       "      <td>0.016177</td>\n",
       "      <td>0.167554</td>\n",
       "      <td>0.749186</td>\n",
       "      <td>0.986855</td>\n",
       "      <td>0.107399</td>\n",
       "      <td>0.377778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>0.045519</td>\n",
       "      <td>0.029289</td>\n",
       "      <td>0.446156</td>\n",
       "      <td>0.499371</td>\n",
       "      <td>0.239768</td>\n",
       "      <td>0.379320</td>\n",
       "      <td>0.775146</td>\n",
       "      <td>0.157582</td>\n",
       "      <td>0.084328</td>\n",
       "      <td>0.166314</td>\n",
       "      <td>0.835237</td>\n",
       "      <td>0.994221</td>\n",
       "      <td>0.146302</td>\n",
       "      <td>0.153333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>506 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           x1        x2        x3        x4        x5        x6        x7  \\\n",
       "0    0.034633  0.206919  0.137057  0.540526  0.193941  0.699239  0.630532   \n",
       "1    0.028920  0.014315  0.276113  0.255945  0.618886  0.555407  0.782263   \n",
       "2    0.020627  0.033230  0.281116  0.525591  0.165269  0.624102  0.586005   \n",
       "3    0.022749  0.033801  0.125044  0.263253  0.251509  0.658532  0.432160   \n",
       "4    0.022148  0.029374  0.121057  0.521126  0.399670  0.448086  0.520158   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "501  0.028702  0.019528  0.455716  0.097575  0.576859  0.588769  0.654701   \n",
       "502  0.034217  0.009498  0.490485  0.372934  0.532351  0.580505  0.750547   \n",
       "503  0.035352  0.021495  0.423918  0.397988  0.349407  0.610529  0.907637   \n",
       "504  0.026182  0.028603  0.443442  0.509663  0.229142  0.667841  0.867135   \n",
       "505  0.045519  0.029289  0.446156  0.499371  0.239768  0.379320  0.775146   \n",
       "\n",
       "           x8        x9       x10       x11       x12       x13     Price  \n",
       "0    0.239410  0.027375  0.209857  0.347609  0.996394  0.102644  0.422222  \n",
       "1    0.482977  0.103031  0.106690  0.520776  0.996650  0.187120  0.368889  \n",
       "2    0.272713  0.036010  0.106986  0.595301  0.983284  0.084079  0.660000  \n",
       "3    0.344932  0.150018  0.068317  0.651297  0.989989  0.015990  0.631111  \n",
       "4    0.495342  0.104383  0.069360  0.560116  0.998723  0.092782  0.693333  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "501  0.188444  0.007595  0.165409  0.736795  0.982923  0.219891  0.386667  \n",
       "502  0.143776  0.051186  0.166428  0.867950  0.995114  0.207453  0.346667  \n",
       "503  0.087385  0.083448  0.164870  0.782704  0.995791  0.094044  0.420000  \n",
       "504  0.236241  0.016177  0.167554  0.749186  0.986855  0.107399  0.377778  \n",
       "505  0.157582  0.084328  0.166314  0.835237  0.994221  0.146302  0.153333  \n",
       "\n",
       "[506 rows x 14 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('data/reg.csv',index_col = 0)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(506, 13)\n",
      "(506, 1)\n"
     ]
    }
   ],
   "source": [
    "x = data.drop('Price',axis=1).to_numpy()\n",
    "y = data['Price'].to_numpy().reshape(-1,1)\n",
    "print(x.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(354, 13)\n",
      "(354, 1)\n",
      "(152, 13)\n",
      "(152, 1)\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size = 0.3)\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class my_ds(Dataset):\n",
    "    def __init__(self, x,y):\n",
    "        self.x = torch.FloatTensor(x)\n",
    "        self.y = torch.FloatTensor(y)\n",
    "        self.len = self.y.size()[0]\n",
    "\n",
    "    def __getitem__(self,index):\n",
    "        return self.x[index],self.y[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindataset = my_ds(x_train,y_train)\n",
    "testdataset = my_ds(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([354, 13])\n",
      "torch.Size([354, 1])\n",
      "torch.Size([152, 13])\n",
      "torch.Size([152, 1])\n"
     ]
    }
   ],
   "source": [
    "print(traindataset.x.size())\n",
    "print(traindataset.y.size())\n",
    "print(testdataset.x.size())\n",
    "print(testdataset.y.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c67384690aacdcb3a89078affff7a8b1615538daeccbff8c2a37b63793d076f9"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('torch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
